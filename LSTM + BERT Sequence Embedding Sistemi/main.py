"""
LSTM + BERT Embedding Hibrit Duygu Analizi Sistemi
- BERT'ten HER KELÄ°ME iÃ§in embedding alÄ±r (sequence)
- LSTM ile sequence'i iÅŸler
- Gemini ile karÅŸÄ±laÅŸtÄ±rÄ±r

KULLANIM:
1. Kaggle'da GPU T4 aktif edin
2. 'egitimveriseti.xlsx' ve Gemini etiketli dosyayÄ± yÃ¼kleyin
3. Bu kodu Ã§alÄ±ÅŸtÄ±rÄ±n
"""

# ===============================
# KÃœTÃœPHANE KURULUMU
# ===============================

print("Gerekli kÃ¼tÃ¼phaneler kontrol ediliyor...\n")

!pip
install
transformers - -quiet
!pip
install
openpyxl - -quiet
!pip
install
tensorflow - -quiet

print("TÃ¼m kÃ¼tÃ¼phaneler hazÄ±r!\n")
print("=" * 70)

# ===============================
# KÃœTÃœPHANE Ä°MPORT
# ===============================

import pandas as pd
import numpy as np
import warnings

warnings.filterwarnings('ignore')

# Transformers (BERT iÃ§in)
from transformers import AutoTokenizer, AutoModel
import torch

# TensorFlow / Keras
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential, load_model, Model
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Input, Masking
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix

# ===============================
# AYARLAR
# ===============================

# Dosya yollarÄ±
EGITIM_DOSYASI = '/kaggle/input/muh-proje3/egitim-veriseti.xlsx'
ETIKETSIZ_DOSYA = '/kaggle/input/muh-proje3/etiketsiz-test-gemini-etiketlenmis.xlsx'
CIKTI_DOSYASI = '/kaggle/working/bert_vs_gemini_sonuc.xlsx'

# Model ayarlarÄ±
BERT_MODEL = 'dbmdz/bert-base-turkish-cased'
MAX_LENGTH = 64  
LSTM_UNITS = 128 
DROPOUT = 0.3  
BATCH_SIZE = 16  
EPOCHS = 20  
LEARNING_RATE = 0.001  

# ===============================
# GPU KONTROLÃœ
# ===============================

print(f"TensorFlow versiyonu: {tf.__version__}")
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"âœ“ GPU tespit edildi: {len(gpus)} adet")
        for gpu in gpus:
            print(f"  - {gpu}")
        print("âœ“ GPU memory growth ayarlandÄ±")
    except RuntimeError as e:
        print(f"GPU ayarÄ± hatasÄ±: {e}")
else:
    print("GPU bulunamadÄ±, CPU kullanÄ±lÄ±yor")

# PyTorch GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"PyTorch device: {device}\n")


# ===============================
# BERT SEQUENCE EMBEDDING EXTRACTION
# ===============================

def extract_bert_sequence_embeddings(texts, tokenizer, model, max_length, batch_size=8):
    """
    BERT'ten cÃ¼mleler iÃ§in SEQUENCE embedding'lerini Ã§Ä±kar
    Her kelime iÃ§in ayrÄ± vektÃ¶r (LSTM iÃ§in gerekli)

    Args:
        texts: Metin listesi
        tokenizer: BERT tokenizer
        model: BERT modeli
        max_length: Maksimum sequence uzunluÄŸu
        batch_size: Batch boyutu

    Returns:
        embeddings: (n_samples, max_length, 768) shape'de numpy array
        attention_masks: (n_samples, max_length) - padding iÃ§in
    """
    model.eval()
    all_embeddings = []
    all_masks = []

    print(f"BERT sequence embedding'leri Ã§Ä±karÄ±lÄ±yor... ({len(texts)} Ã¶rnek)")
    print(f"   Her cÃ¼mle iÃ§in {max_length} token Ã— 768 boyut = sequence")

    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]

        # Tokenize (padding ve truncation)
        encoded = tokenizer(
            batch_texts,
            padding='max_length',
            truncation=True,
            max_length=max_length,
            return_tensors='pt'
        )

        
        input_ids = encoded['input_ids'].to(device)
        attention_mask = encoded['attention_mask'].to(device)

        # BERT'ten TÃœM token'larÄ±n embedding'lerini al
        with torch.no_grad():
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            # last_hidden_state: (batch_size, sequence_length, 768)
            sequence_embeddings = outputs.last_hidden_state.cpu().numpy()
            attention_masks = attention_mask.cpu().numpy()

            all_embeddings.append(sequence_embeddings)
            all_masks.append(attention_masks)

        if (i // batch_size + 1) % 10 == 0:
            print(f"  Ä°ÅŸlenen: {min(i + batch_size, len(texts))}/{len(texts)}")

    embeddings = np.vstack(all_embeddings)
    masks = np.vstack(all_masks)

    print(f"âœ“ Sequence Embedding shape: {embeddings.shape}")
    print(f"  â†’ {embeddings.shape[0]} cÃ¼mle")
    print(f"  â†’ {embeddings.shape[1]} token/cÃ¼mle (sequence length)")
    print(f"  â†’ {embeddings.shape[2]} boyutlu vektÃ¶r/token")

    return embeddings, masks


# ===============================
# ANA PROGRAM
# ===============================

print("=" * 70)
print("LSTM + BERT SEQUENCE EMBEDDING SÄ°STEMÄ°")
print("=" * 70)

# ===============================
# 1. BERT MODELÄ°NÄ° YÃœKLE
# ===============================

print("\nADIM 1: BERT modeli yÃ¼kleniyor (sequence embedding iÃ§in)...")
tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL)
bert_model = AutoModel.from_pretrained(BERT_MODEL).to(device)
bert_model.eval()
print("âœ“ BERT hazÄ±r (her kelime iÃ§in embedding Ã§Ä±karacak)")

# ===============================
# 2. EÄžÄ°TÄ°M VERÄ°SÄ°NÄ° YÃœKLE
# ===============================

print("\nADIM 2: EÄŸitim verisi yÃ¼kleniyor...")
df = pd.read_excel(EGITIM_DOSYASI)
print(f"âœ“ {len(df)} Ã¶rnek yÃ¼klendi")

# Label mapping
label_map = {'pozitif': 2, 'negatif': 0, 'nÃ¶tr': 1}
df['label'] = df['sentiment'].map(label_map)

print("\nSÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±:")
for sentiment, count in df['sentiment'].value_counts().items():
    percentage = (count / len(df)) * 100
    print(f"  {sentiment}: {count} (%{percentage:.1f})")

# ===============================
# 3. VERÄ°YÄ° BÃ–L
# ===============================

print("\nADIM 3: Veri bÃ¶lÃ¼nÃ¼yor (stratified split)...")

train_df, temp_df = train_test_split(df, train_size=0.8, random_state=42, stratify=df['label'])
val_df, test_df = train_test_split(temp_df, train_size=0.5, random_state=42, stratify=temp_df['label'])

print(f"âœ“ EÄŸitim seti: {len(train_df)} Ã¶rnek")
print(f"âœ“ DoÄŸrulama seti: {len(val_df)} Ã¶rnek")
print(f"âœ“ Test seti: {len(test_df)} Ã¶rnek")

# ===============================
# 4. BERT SEQUENCE EMBEDDING'LERÄ°NÄ° Ã‡IKAR
# ===============================

print("\nADIM 4: BERT sequence embedding'leri Ã§Ä±karÄ±lÄ±yor...")
print("(Her kelime iÃ§in ayrÄ± vektÃ¶r - LSTM iÃ§in gerekli!)")
print("(Bu iÅŸlem biraz zaman alabilir...)\n")

# EÄŸitim seti
X_train_seq, X_train_masks = extract_bert_sequence_embeddings(
    train_df['text'].tolist(),
    tokenizer,
    bert_model,
    MAX_LENGTH
)

# DoÄŸrulama seti
X_val_seq, X_val_masks = extract_bert_sequence_embeddings(
    val_df['text'].tolist(),
    tokenizer,
    bert_model,
    MAX_LENGTH
)

# Test seti
X_test_seq, X_test_masks = extract_bert_sequence_embeddings(
    test_df['text'].tolist(),
    tokenizer,
    bert_model,
    MAX_LENGTH
)

# Label'lar
y_train = train_df['label'].values
y_val = val_df['label'].values
y_test = test_df['label'].values

print(f"\nâœ“ Sequence Embedding'ler hazÄ±r!")
print(f"  Train shape: {X_train_seq.shape} (samples Ã— sequence Ã— embedding_dim)")
print(f"  Val shape: {X_val_seq.shape}")
print(f"  Test shape: {X_test_seq.shape}")

# BERT modelini bellekten temizleme
del bert_model
torch.cuda.empty_cache()
print("\nâœ“ BERT modeli bellekten temizlendi (artÄ±k sadece LSTM kullanÄ±lacak)")

# ===============================
# 5. GERÃ‡EK LSTM MODELÄ°NÄ° OLUÅžTUR
# ===============================

print("\nADIM 5: GERÃ‡EK LSTM modeli oluÅŸturuluyor...")
print("(Input: BERT sequence embeddings - her kelime iÃ§in 768-dim vektÃ¶r)")


model = Sequential([
    # Input: Sequence of embeddings (max_length, 768)
    Input(shape=(MAX_LENGTH, 768)),

    # Masking layer (padding iÃ§in)
    Masking(mask_value=0.0),

    # Bidirectional LSTM (hem ileri hem geri oku)
    Bidirectional(LSTM(LSTM_UNITS, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)),

    # Ä°kinci LSTM katmanÄ±
    Bidirectional(LSTM(LSTM_UNITS // 2, dropout=0.2, recurrent_dropout=0.2)),

    # Dense katmanlar
    Dense(64, activation='relu'),
    Dropout(DROPOUT),

    Dense(32, activation='relu'),
    Dropout(DROPOUT),

    # Ã‡Ä±kÄ±ÅŸ katmanÄ±
    Dense(3, activation='softmax')
])

# Model derleme
model.compile(
    optimizer=Adam(learning_rate=LEARNING_RATE),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print("\nModel Mimarisi:")
model.summary()

print("\nBu model:")
print("  1. BERT'ten gelen sequence'i alÄ±yor (her kelime ayrÄ± vektÃ¶r)")
print("  2. Bidirectional LSTM ile hem ileri hem geri okuyor")
print("  3. Ä°kinci LSTM katmanÄ± ile Ã¶zetliyor")
print("  4. Dense katmanlarla sÄ±nÄ±flandÄ±rÄ±yor")

# ===============================
# 6. CALLBACK'LER
# ===============================

callbacks = [
    ModelCheckpoint(
        'best_real_lstm_bert_model.h5',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    ),
    EarlyStopping(
        monitor='val_accuracy',
        patience=5,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=3,
        min_lr=0.00001,
        verbose=1
    )
]

# ===============================
# 7. MODEL EÄžÄ°TÄ°MÄ°
# ===============================

print("\n" + "=" * 70)
print("ðŸŽ“ ADIM 6: MODEL EÄžÄ°TÄ°MÄ° BAÅžLIYOR")
print("=" * 70)
print(f"Maksimum epoch: {EPOCHS}")
print(f"Batch size: {BATCH_SIZE}")
print(f"Learning rate: {LEARNING_RATE}")
print(f"Input: BERT sequence embeddings ({MAX_LENGTH} Ã— 768)")
print(f"LSTM: Bidirectional (2 katman)")
print(f"Early stopping: 5 epoch patience\n")

history = model.fit(
    X_train_seq, y_train,
    validation_data=(X_val_seq, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=callbacks,
    verbose=1
)

print("\nâœ“ EÄŸitim tamamlandÄ±!")

# ===============================
# 8. TEST SETÄ° DEÄžERLENDÄ°RMESÄ°
# ===============================

print("\n" + "=" * 70)
print("ADIM 7: TEST SETÄ° DEÄžERLENDÄ°RMESÄ°")
print("=" * 70)

# Test seti tahminleri
test_loss, test_accuracy = model.evaluate(X_test_seq, y_test, verbose=0)
test_predictions = model.predict(X_test_seq, verbose=0)
test_pred_classes = np.argmax(test_predictions, axis=1)

# Metrikler
precision, recall, f1, _ = precision_recall_fscore_support(y_test, test_pred_classes, average='weighted')

print(f"\nTest SonuÃ§larÄ±:")
print(f"  Accuracy:  {test_accuracy:.4f}")
print(f"  Precision: {precision:.4f}")
print(f"  Recall:    {recall:.4f}")
print(f"  F1 Score:  {f1:.4f}")

print("\nDetaylÄ± SÄ±nÄ±flandÄ±rma Raporu:")
label_names = ['negatif', 'nÃ¶tr', 'pozitif']
print(classification_report(y_test, test_pred_classes, target_names=label_names))

print("\nKarmaÅŸÄ±klÄ±k Matrisi:")
cm = confusion_matrix(y_test, test_pred_classes)
print("\n              Tahmin Edilen")
print("          negatif  nÃ¶tr  pozitif")
for i, label in enumerate(label_names):
    print(f"GerÃ§ek {label:8s}  {cm[i][0]:4d}  {cm[i][1]:4d}  {cm[i][2]:4d}")

# ===============================
# 9. YENÄ° VERÄ° SETÄ°NÄ° ETÄ°KETLE
# ===============================

print("\n" + "=" * 70)
print("ADIM 8: YENÄ° VERÄ° SETÄ° ETÄ°KETLENÄ°YOR")
print("=" * 70)

try:
    
    print(f"\nDosya okunuyor: {ETIKETSIZ_DOSYA}")
    new_df = pd.read_excel(ETIKETSIZ_DOSYA)
    print(f"âœ“ {len(new_df)} Ã¶rnek yÃ¼klendi")

    if 'text' not in new_df.columns:
        print("HATA: Excel dosyasÄ±nda 'text' sÃ¼tunu bulunamadÄ±!")
    else:
        # Gemini etiketlerini yedekle
        if 'sentiment' in new_df.columns:
            new_df['gemini_sentiment'] = new_df['sentiment']
            print("âœ“ Gemini etiketleri 'gemini_sentiment' sÃ¼tununa yedeklendi")

        # BERT'i tekrar yÃ¼kle (tahmin iÃ§in)
        print("\nBERT modeli yeniden yÃ¼kleniyor (tahmin iÃ§in)...")
        bert_model = AutoModel.from_pretrained(BERT_MODEL).to(device)
        bert_model.eval()

        # Yeni veriler iÃ§in BERT sequence embedding'leri Ã§Ä±kar
        X_new_seq, X_new_masks = extract_bert_sequence_embeddings(
            new_df['text'].tolist(),
            tokenizer,
            bert_model,
            MAX_LENGTH
        )

        # LSTM ile tahmin yap
        print("\nLSTM tahminleri yapÄ±lÄ±yor...")
        predictions = model.predict(X_new_seq, batch_size=32, verbose=1)
        pred_classes = np.argmax(predictions, axis=1)

        label_map_reverse = {0: 'negatif', 1: 'nÃ¶tr', 2: 'pozitif'}
        new_df['real_lstm_bert_sentiment'] = [label_map_reverse[p] for p in pred_classes]
        new_df['real_lstm_bert_conf_negatif'] = predictions[:, 0]
        new_df['real_lstm_bert_conf_notr'] = predictions[:, 1]
        new_df['real_lstm_bert_conf_pozitif'] = predictions[:, 2]
        new_df['real_lstm_bert_conf_score'] = np.max(predictions, axis=1)

        # Kaydet
        new_df.to_excel(CIKTI_DOSYASI, index=False)
        print(f"\nSonuÃ§lar '{CIKTI_DOSYASI}' dosyasÄ±na kaydedildi!")

        print("\nGERÃ‡EK LSTM+BERT Tahmin DaÄŸÄ±lÄ±mÄ±:")
        for sentiment, count in new_df['real_lstm_bert_sentiment'].value_counts().items():
            percentage = (count / len(new_df)) * 100
            print(f"  {sentiment}: {count} (%{percentage:.1f})")

        print(f"\nGERÃ‡EK LSTM+BERT ortalama gÃ¼ven skoru: {new_df['real_lstm_bert_conf_score'].mean():.4f}")

        # ===============================
        # 10. GEMÄ°NÄ° VS LSTM+BERT KARÅžILAÅžTIRMA
        # ===============================

        if 'gemini_sentiment' in new_df.columns:
            print("\n" + "=" * 70)
            print("GEMÄ°NÄ° VS GERÃ‡EK LSTM+BERT KARÅžILAÅžTIRMASI")
            print("=" * 70)

            # GerÃ§ek etiketleri sayÄ±sal formata Ã§evir
            true_labels = new_df['gemini_sentiment'].map(label_map).values
            predicted_labels = [label_map[pred] for pred in new_df['real_lstm_bert_sentiment']]

            # Metrikler
            accuracy = accuracy_score(true_labels, predicted_labels)
            precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels,
                                                                       average='weighted')

            print("\nGERÃ‡EK LSTM+BERT'Ã¼n GEMÄ°NÄ° ETÄ°KETLERÄ°NE GÃ–RE BAÅžARI ORANI:")
            print(f"  âœ“ Accuracy:  {accuracy:.4f}  ({accuracy * 100:.2f}%)")
            print(f"  âœ“ Precision: {precision:.4f}")
            print(f"  âœ“ Recall:    {recall:.4f}")
            print(f"  âœ“ F1 Score:  {f1:.4f}")

            # UyuÅŸma analizi
            agreement = (new_df['gemini_sentiment'] == new_df['real_lstm_bert_sentiment']).sum()
            disagreement = len(new_df) - agreement

            print(f"\nUYUÅžMA ANALÄ°ZÄ°:")
            print(f"  UyuÅŸan tahminler: {agreement} (%{(agreement / len(new_df)) * 100:.2f})")
            print(f"  FarklÄ± tahminler: {disagreement} (%{(disagreement / len(new_df)) * 100:.2f})")

            # SÄ±nÄ±f bazÄ±nda detaylÄ± rapor
            print("\nSINIF BAZINDA KARÅžILAÅžTIRMA:")
            print(classification_report(true_labels, predicted_labels, target_names=label_names))

            # Confusion Matrix
            print("\nKARMAÅžIKLIK MATRÄ°SÄ° (Gemini vs GERÃ‡EK LSTM+BERT):")
            cm = confusion_matrix(true_labels, predicted_labels)
            print("\n                  LSTM+BERT Tahmini")
            print("              negatif  nÃ¶tr  pozitif")
            for i, label in enumerate(label_names):
                print(f"Gemini {label:8s}  {cm[i][0]:4d}   {cm[i][1]:4d}   {cm[i][2]:4d}")

            # FarklÄ± tahmin Ã¶rnekleri
            print("\nFARKLI TAHMÄ°N Ã–RNEKLERÄ° (Ä°lk 10):")
            different_predictions = new_df[new_df['gemini_sentiment'] != new_df['real_lstm_bert_sentiment']].head(10)

            if len(different_predictions) > 0:
                for idx, row in different_predictions.iterrows():
                    print(f"\n  CÃ¼mle: {row['text'][:80]}...")
                    print(
                        f"     Gemini: {row['gemini_sentiment']:8s} | LSTM+BERT: {row['real_lstm_bert_sentiment']:8s} | GÃ¼ven: {row['real_lstm_bert_conf_score']:.3f}")
            else:
                print("TÃ¼m tahminler uyuÅŸuyor!")

            # GÃ¼ven skoruna gÃ¶re analiz
            print("\nGÃœVEN SKORUNA GÃ–RE ANALÄ°Z:")

            agreement_mask = new_df['gemini_sentiment'] == new_df['real_lstm_bert_sentiment']

            avg_confidence_agree = new_df[agreement_mask]['real_lstm_bert_conf_score'].mean()
            avg_confidence_disagree = new_df[~agreement_mask]['real_lstm_bert_conf_score'].mean()

            print(f"  UyuÅŸan tahminlerde LSTM+BERT gÃ¼veni: {avg_confidence_agree:.4f}")
            print(f"  FarklÄ± tahminlerde LSTM+BERT gÃ¼veni: {avg_confidence_disagree:.4f}")

            # DÃ¼ÅŸÃ¼k gÃ¼venli farklÄ± tahminler
            low_conf_different = new_df[(~agreement_mask) & (new_df['real_lstm_bert_conf_score'] < 0.7)]
            print(f"\n  DÃ¼ÅŸÃ¼k gÃ¼venle farklÄ± tahmin edilen: {len(low_conf_different)} adet")

            if len(low_conf_different) > 0:
                print(f"  (Bu tahminler belirsiz olabilir, manuel kontrol Ã¶nerilir)")

            # SÄ±nÄ±f bazÄ±nda uyuÅŸma
            print("\nSINIF BAZINDA UYUÅžMA ORANLARI:")
            for sentiment in ['pozitif', 'negatif', 'nÃ¶tr']:
                gemini_subset = new_df[new_df['gemini_sentiment'] == sentiment]
                if len(gemini_subset) > 0:
                    agree_count = (gemini_subset['gemini_sentiment'] == gemini_subset['real_lstm_bert_sentiment']).sum()
                    agree_pct = (agree_count / len(gemini_subset)) * 100
                    print(f"  {sentiment:8s}: {agree_count}/{len(gemini_subset)} (%{agree_pct:.1f})")

except FileNotFoundError:
    print(f"\n'{ETIKETSIZ_DOSYA}' dosyasÄ± bulunamadÄ±!")
    print("   DosyayÄ± yÃ¼kleyin ve ETIKETSIZ_DOSYA deÄŸiÅŸkenini gÃ¼ncelleyin.")

# ===============================
# 11. MODEL KAYDET
# ===============================

print("\n" + "=" * 70)
print("ADIM 9: Model kaydediliyor...")

model.save('real_lstm_bert_model.h5')

import pickle

config = {
    'bert_model': BERT_MODEL,
    'max_length': MAX_LENGTH,
    'lstm_units': LSTM_UNITS
}
with open('real_lstm_bert_config.pickle', 'wb') as f:
    pickle.dump(config, f)

print("âœ“ Model 'real_lstm_bert_model.h5' olarak kaydedildi!")
print("âœ“ Config 'real_lstm_bert_config.pickle' olarak kaydedildi!")

print("\n" + "=" * 70)
print("TAMAMLANDI!")
print("=" * 70)
print("\nSonuÃ§lar:")
print(f"1. âœ“ KarÅŸÄ±laÅŸtÄ±rma dosyasÄ±: {CIKTI_DOSYASI}")
print("2. âœ“ Model dosyasÄ±: real_lstm_bert_model.h5")
print("3. âœ“ Config: real_lstm_bert_config.pickle")
print("4. âœ“ Gemini vs GERÃ‡EK LSTM+BERT karÅŸÄ±laÅŸtÄ±rmasÄ± tamamlandÄ±")
print("\nBu model:")
print("BERT'ten HER KELÄ°ME iÃ§in embedding alÄ±yor (sequence)")
print("Bidirectional LSTM ile sequence'i iÅŸliyor")
print("GerÃ§ek anlamda 'LSTM + BERT Embedding' yapÄ±yor")
print("\nBeklenen performans: %89-92 accuracy")
print("   (Ã–nceki Dense versiyondan %2-4 daha iyi olmalÄ±)")
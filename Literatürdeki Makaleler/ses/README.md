# Ses Veri ArtÄ±rÄ±mÄ± ve Sentezi Ãœzerine LiteratÃ¼r Derlemesi

Bu repo, ses sÄ±nÄ±flandÄ±rma, konuÅŸmacÄ± doÄŸrulama ve anahtar kelime tanÄ±ma gibi alanlarda model performansÄ±nÄ± iyileÅŸtirmek amacÄ±yla sentetik ses verisi Ã¼retimi ve veri artÄ±rÄ±mÄ± Ã¼zerine yapÄ±lmÄ±ÅŸ akademik Ã§alÄ±ÅŸmalarÄ± bir araya getirmektedir. Ã–zellikle sÄ±nÄ±rlÄ± veri kÃ¼meleriyle Ã§alÄ±ÅŸÄ±rken karÅŸÄ±laÅŸÄ±lan zorluklara Ã§Ã¶zÃ¼m olarak sunulan modern teknikler incelenmektedir.

## ğŸ“œ Genel BakÄ±ÅŸ

[cite_start]Derin Ã¶ÄŸrenme tabanlÄ± ses iÅŸleme modelleri, yÃ¼ksek performans elde etmek iÃ§in genellikle bÃ¼yÃ¼k miktarda etiketli veriye ihtiyaÃ§ duyar[cite: 2129]. [cite_start]Ancak, gerÃ§ek dÃ¼nya verisi toplamak ve etiketlemek maliyetli ve zaman alÄ±cÄ± bir sÃ¼reÃ§tir[cite: 2130]. Bu noktada, veri artÄ±rÄ±mÄ± (data augmentation) ve sentetik veri Ã¼retimi (synthetic data generation) kritik bir rol oynamaktadÄ±r.

Bu derlemede incelenen makaleler, aÅŸaÄŸÄ±daki temel sorulara odaklanmaktadÄ±r:

* **Veri ArtÄ±rÄ±mÄ±:** Mevcut ses verilerini kullanarak yeni ve Ã§eÅŸitli Ã¶rnekler nasÄ±l oluÅŸturulabilir?
* **Sentetik Veri Ãœretimi:** Metinden sese (Text-to-Audio) veya ses dÃ¶nÃ¼ÅŸÃ¼mÃ¼ (Voice Conversion) gibi tekniklerle sÄ±fÄ±rdan gerÃ§ekÃ§i ses verileri nasÄ±l Ã¼retilebilir?
* **Performans Etkisi:** Bu teknikler, ses sÄ±nÄ±flandÄ±rma ve doÄŸrulama sistemlerinin doÄŸruluÄŸunu ve saÄŸlamlÄ±ÄŸÄ±nÄ± ne Ã¶lÃ§Ã¼de iyileÅŸtirmektedir?

---

## ğŸ”¬ Ä°ncelenen Teknikler ve YÃ¶ntemler

Bu derlemede Ã¶ne Ã§Ä±kan ana yaklaÅŸÄ±mlar aÅŸaÄŸÄ±da Ã¶zetlenmiÅŸtir.

### 1. Ses TabanlÄ± Veri ArtÄ±rÄ±mÄ± (Audio-based Augmentation)

Bu teknikler doÄŸrudan ses dalga formuna veya onun gÃ¶rsel temsillerine (spektrogram, skalogram) uygulanÄ±r.

* **Dalga Formu ManipÃ¼lasyonlarÄ±**:
    * [cite_start]**GÃ¼rÃ¼ltÃ¼ Ekleme (Noise Addition):** GerÃ§ek dÃ¼nya koÅŸullarÄ±nÄ± simÃ¼le etmek iÃ§in sinyale Ã§evresel veya rastgele gÃ¼rÃ¼ltÃ¼ eklenir[cite: 655, 1842].
    * [cite_start]**Zaman Esnetme (Time Stretching):** Sesin perdesini deÄŸiÅŸtirmeden hÄ±zÄ±nÄ± ayarlar[cite: 655, 2252].
    * [cite_start]**Perde KaydÄ±rma (Pitch Shifting):** Sesin hÄ±zÄ±nÄ± deÄŸiÅŸtirmeden perdesini (frekansÄ±nÄ±) ayarlar[cite: 655, 1670, 1842, 2252].
    * [cite_start]**Ses KontrolÃ¼ (Volume Control):** FarklÄ± kayÄ±t seviyelerini taklit etmek iÃ§in genliÄŸi deÄŸiÅŸtirir[cite: 655].
* **GÃ¶rsel Temsil ManipÃ¼lasyonlarÄ±**:
    * Sesin **skalogram** gibi gÃ¶rsel temsillerine geometrik dÃ¶nÃ¼ÅŸÃ¼mler uygulanÄ±r:
        * [cite_start]DÃ¶ndÃ¼rme (Rotation) [cite: 656]
        * [cite_start]Ã–lÃ§ekleme (Scaling) [cite: 656]
        * [cite_start]KÄ±rpma (Shearing) [cite: 656]
        * [cite_start]Ã–teleme (Translation) [cite: 656]

### 2. Ãœretken Modellerle Sentetik Veri Ãœretimi

Bu yaklaÅŸÄ±m, mevcut verileri dÃ¶nÃ¼ÅŸtÃ¼rmek yerine tamamen yeni ses Ã¶rnekleri oluÅŸturmaya odaklanÄ±r.

* **Metinden Sese (Text-to-Audio - TTA) Modelleri**:
    * [cite_start]**AudioGen** ve **AudioLDM2** gibi modeller, metinsel aÃ§Ä±klamalardan (prompt) gerÃ§ekÃ§i sesler Ã¼retebilir[cite: 657, 2124, 2125].
    * [cite_start]Bu yÃ¶ntem, Ã¶zellikle veri toplamanÄ±n zor olduÄŸu nadir ses olaylarÄ± iÃ§in eÄŸitim setlerini zenginleÅŸtirmede oldukÃ§a etkilidir[cite: 2128].
    * [cite_start]ChatGPT gibi bÃ¼yÃ¼k dil modelleri (LLM'ler) kullanÄ±larak daha Ã§eÅŸitli ve baÄŸlamsal olarak zengin prompt'lar oluÅŸturulabilir[cite: 2191, 2194].
* **Ses DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (Voice Conversion - VC)**:
    * [cite_start]Bir konuÅŸmacÄ±nÄ±n sesini (kaynak) baÅŸka bir konuÅŸmacÄ±nÄ±n sesine (hedef) dÃ¶nÃ¼ÅŸtÃ¼rerek aynÄ± iÃ§eriÄŸe sahip yeni ses Ã¶rnekleri oluÅŸturur[cite: 1736, 1743].
    * [cite_start]Ã–zellikle metne baÄŸlÄ± konuÅŸmacÄ± doÄŸrulama (text-dependent speaker verification) gibi gÃ¶revlerde, sÄ±nÄ±rlÄ± sayÄ±da konuÅŸmacÄ±dan daha fazla Ã§eÅŸitlilik elde etmek iÃ§in kullanÄ±lÄ±r[cite: 1514, 1517, 1529].
    * [cite_start]**CycleGAN** ve **Autoencoder** tabanlÄ± modeller bu alanda Ã¶ne Ã§Ä±kan yaklaÅŸÄ±mlardÄ±r[cite: 108, 112].

---

## ğŸ“Š Ana Bulgular ve SonuÃ§lar

Ä°ncelenen makalelerdeki temel bulgular ÅŸunlardÄ±r:

* [cite_start]**Veri ArtÄ±rÄ±mÄ± PerformansÄ± Ä°yileÅŸtirir:** Hem ses tabanlÄ± artÄ±rÄ±m teknikleri hem de sentetik veri Ã¼retimi, ses sÄ±nÄ±flandÄ±rma modellerinin doÄŸruluÄŸunu genellikle artÄ±rmaktadÄ±r[cite: 662, 1409, 2131]. [cite_start]VGGish modelinde %9.05'e varan doÄŸruluk artÄ±ÅŸlarÄ± gÃ¶zlemlenmiÅŸtir[cite: 664].
* [cite_start]**AÅŸÄ±rÄ± KullanÄ±m Riskleri:** Veri setini artÄ±rÄ±rken belirli bir eÅŸiÄŸin (%100-%200 artÄ±ÅŸ) Ã¼zerine Ã§Ä±kmak, modelin aÅŸÄ±rÄ± Ã¶ÄŸrenmesine (overfitting) ve performans dÃ¼ÅŸÃ¼ÅŸÃ¼ne neden olabilir[cite: 962, 1337].
* **TTA ve VC'nin GÃ¼cÃ¼:**
    * [cite_start]TTA modelleri ile Ã¼retilen veriler, veri artÄ±rÄ±mÄ± iÃ§in kullanÄ±ldÄ±ÄŸÄ±nda geleneksel sinyal iÅŸleme tabanlÄ± yÃ¶ntemlerden daha iyi sonuÃ§lar vermiÅŸtir[cite: 2259, 2260].
    * [cite_start]Ancak, bir modeli **sadece** sentetik verilerle eÄŸitmek, gerÃ§ek veriler Ã¼zerinde test edildiÄŸinde genellikle daha dÃ¼ÅŸÃ¼k performansa yol aÃ§ar[cite: 2118, 2278].
    * [cite_start]GerÃ§ek verilerin bir kÄ±smÄ±nÄ± (%20-%40) sentetik verilerle deÄŸiÅŸtirmek, performanstan Ã¶nemli bir kayÄ±p yaÅŸamadan veri toplama maliyetini dÃ¼ÅŸÃ¼rme potansiyeli sunar[cite: 2332].
* [cite_start]**GÃ¼rÃ¼ltÃ¼ye KarÅŸÄ± DayanÄ±klÄ±lÄ±k:** GÃ¼rÃ¼ltÃ¼ ekleme gibi artÄ±rÄ±m teknikleri, modelleri Ã§eÅŸitli ve gÃ¼rÃ¼ltÃ¼lÃ¼ ortamlara karÅŸÄ± daha saÄŸlam hale getirir[cite: 1733, 1740].

---

## ğŸš€ Uygulama AlanlarÄ±

Bu teknikler, aÅŸaÄŸÄ±daki gibi birÃ§ok pratik alanda deÄŸerlidir:

* [cite_start]**AkÄ±llÄ± Åehirler:** Cam kÄ±rÄ±lmasÄ±, insan Ã§Ä±ÄŸlÄ±ÄŸÄ± gibi nadir seslerin tespiti[cite: 681, 709].
* [cite_start]**EndÃ¼striyel BakÄ±m:** Makinelerdeki anormal sesleri tespit ederek kestirimci bakÄ±m yapma[cite: 681, 709].
* [cite_start]**SaÄŸlÄ±k:** Ã–ksÃ¼rÃ¼k, anormal nefes alma gibi sesleri analiz ederek teÅŸhise yardÄ±mcÄ± olma[cite: 681, 709].
* [cite_start]**GÃ¼venlik:** Ã–zelleÅŸtirilmiÅŸ uyandÄ±rma kelimeleri (wake-up words) ile konuÅŸmacÄ± doÄŸrulama sistemleri geliÅŸtirme[cite: 1529].

---

## âš ï¸ Sorumluluk Reddi ve KullanÄ±m AmacÄ±
Bu depoda Ã¶zetlenen ve referans olarak gÃ¶sterilen tÃ¼m akademik makaleler kamuya aÃ§Ä±k, Ã§evrimiÃ§i ve eriÅŸilebilir kaynaklardan temin edilmiÅŸtir.

Bu derlemenin ve ilgili materyallerin temel amacÄ±, sentetik veri Ã¼retimi ve veri artÄ±rÄ±mÄ± alanÄ±ndaki mevcut bilimsel Ã§alÄ±ÅŸmalarÄ± eÄŸitim ve bilgilendirme hedefiyle bir araya getirmektir. KullanÄ±cÄ±larÄ±n, atÄ±fta bulunulan her bir makalenin orijinal kaynaÄŸÄ±nÄ± incelemeleri ve o kaynaÄŸÄ±n belirttiÄŸi lisans koÅŸullarÄ±na uymalarÄ± beklenmektedir. TÃ¼m Ã§alÄ±ÅŸmalarÄ±n haklarÄ± orijinal yazarlarÄ±na ve yayÄ±ncÄ±larÄ±na aittir.

---

## ğŸ“š Makalelerin KaynaklarÄ±

[1] E. Tsalera, A. Papadakis, G. Pagiatakis, and M. Samarakou, "Impact Evaluation of Sound Dataset Augmentation and Synthetic Generation upon Classification Accuracy," J. Sens. Actuator Netw., vol. 14, no. 91, 2025.

[2] F. Ronchini, L. Comanducci, and F. Antonacci, "Synthetic Training Set Generation Using Text-to-Audio Models for Environmental Sound Classification," arXiv preprint arXiv:2403.17864, 2024.

[3] O. Slizovskaia, J. Janer, P. Chandna, and O. Mayor, "Voice Conversion with Limited Data and Limitless Data Augmentations," arXiv preprint arXiv:2212.13581, 2022.

[4] X. Qin, Y. Yang, L. Yang, X. Wang, J. Wang, and M. Li, "Exploring Voice Conversion Based Data Augmentation in Text-Dependent Speaker Verification," arXiv preprint arXiv:2011.10710, 2020.

[5] Y. A. Wubet and K.-Y. Lian, "Voice Conversion Based Augmentation and a Hybrid CNN-LSTM Model for Improving Speaker-Independent Keyword Recognition on Limited Datasets," IEEE Access, vol. 10, pp. 89170-89181, 2022.

[6] A. Tanna, M. Saxon, A. El Abbadi, and W. Y. Wang, "Data Augmentation for Diverse Voice Conversion in Noisy Environments," arXiv preprint arXiv:2305.10684, 2023.
# ğŸ¤– TÃ¼rkÃ§e Sentetik Veri Ãœretimi ve NLP: KapsamlÄ± KarÅŸÄ±laÅŸtÄ±rmalÄ± Ã‡alÄ±ÅŸma

[![License](https://img.shields.io/badge/License-Proprietary-red.svg)](LICENSE.md)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.x-red.svg)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/ğŸ¤—%20Transformers-4.x-yellow.svg)](https://huggingface.co/transformers/)

Bu proje, **TÃ¼rkÃ§e metinler** iÃ§in sentetik veri Ã¼retimi ve duygu analizi Ã¼zerine **9 farklÄ± derin Ã¶ÄŸrenme ve AI yaklaÅŸÄ±mÄ±nÄ±n** kapsamlÄ± karÅŸÄ±laÅŸtÄ±rmalÄ± analizini sunar. Proje kapsamÄ±nda **BERT**, **LSTM**, **BiLSTM**, **GAN**, **GPT-2**, **mT5**, **Gemini API** ve **Character-level LSTM** modelleri kullanÄ±larak hem veri Ã¼retimi hem de duygu sÄ±nÄ±flandÄ±rmasÄ± gerÃ§ekleÅŸtirilmiÅŸtir.

---

## ğŸ“‹ Ä°Ã§indekiler

- [Proje HakkÄ±nda](#-proje-hakkÄ±nda)
- [YÃ¶ntemler ve SonuÃ§lar](#-yÃ¶ntemler-ve-sonuÃ§lar)
- [KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz](#-karÅŸÄ±laÅŸtÄ±rmalÄ±-analiz)
- [Proje YapÄ±sÄ±](#-proje-yapÄ±sÄ±)
- [Kurulum](#-kurulum)
- [KullanÄ±m](#-kullanÄ±m)
- [Performans Metrikleri](#-performans-metrikleri)
- [LiteratÃ¼r AraÅŸtÄ±rmasÄ±](#-literatÃ¼r-araÅŸtÄ±rmasÄ±)
- [Lisans](#-lisans)

---

## ğŸ¯ Proje HakkÄ±nda

Bu araÅŸtÄ±rma projesi, **elektrikli arabalar** konusunda TÃ¼rkÃ§e sentetik veri Ã¼retimi ve duygu analizi iÃ§in dÃ¶rt farklÄ± derin Ã¶ÄŸrenme yaklaÅŸÄ±mÄ±nÄ± kapsamlÄ± bir ÅŸekilde incelemektedir:

### ğŸ”¬ AraÅŸtÄ±rma SorularÄ±
1. Hangi model TÃ¼rkÃ§e metinler iÃ§in en yÃ¼ksek duygu analizi doÄŸruluÄŸunu saÄŸlar?
2. GAN, GPT-2, BERT MLM, mT5 ve Character-level LSTM hangi senaryolarda Ã¼stÃ¼n performans gÃ¶sterir?
3. Pre-trained modeller (BERT, GPT-2, mT5) ile sÄ±fÄ±rdan eÄŸitilen modeller (LSTM, GAN) arasÄ±ndaki fark nedir?
4. Gemini AI ile geleneksel modeller arasÄ±ndaki uyuÅŸma oranÄ± nedir?
5. 100 cÃ¼mleden 3000 cÃ¼mle Ã¼retiminde hangi yÃ¶ntem en kaliteli sonuÃ§larÄ± verir?

### ğŸ“ KullanÄ±m AlanlarÄ±
- DoÄŸal Dil Ä°ÅŸleme (NLP) araÅŸtÄ±rmalarÄ±
- Sentetik veri Ã¼retimi iÃ§in benchmark Ã§alÄ±ÅŸmalarÄ±
- TÃ¼rkÃ§e duygu analizi model karÅŸÄ±laÅŸtÄ±rmalarÄ±
- EÄŸitim ve akademik projeler
- LiteratÃ¼r taramasÄ± ve state-of-the-art teknik incelemesi

---

## ğŸš€ YÃ¶ntemler ve SonuÃ§lar

### 1ï¸âƒ£ **BERT ile Duygu Analizi**
ğŸ“‚ KlasÃ¶r: `/bert-sentiment-analysis/`

**Ã–zellikler:**
- `dbmdz/bert-base-turkish-cased` modeli kullanÄ±mÄ±
- 3 sÄ±nÄ±flÄ± duygu analizi (Pozitif, Negatif, NÃ¶tr)
- Fine-tuning ile TÃ¼rkÃ§e'ye Ã¶zelleÅŸtirilmiÅŸ model
- Gemini AI ile karÅŸÄ±laÅŸtÄ±rmalÄ± deÄŸerlendirme

**Performans:**
- âœ… **Test DoÄŸruluÄŸu:** %92.6
- âœ… **Gemini UyuÅŸma:** %92.3
- âœ… **En Ä°yi SÄ±nÄ±f:** Negatif (%98)
- âš ï¸ **ZayÄ±f Nokta:** NÃ¶tr sÄ±nÄ±f (%84)

**KullanÄ±lan Teknolojiler:**
- Transformers (Hugging Face)
- PyTorch
- pandas, scikit-learn

---

### 2ï¸âƒ£ **BiLSTM + BERT Sequence Embedding**
ğŸ“‚ KlasÃ¶r: `/bilstm-bert-hybrid/`

**Ã–zellikler:**
- BERT sequence embeddings (768-boyutlu vektÃ¶rler)
- 2 katmanlÄ± Bidirectional LSTM
- Kelime sÄ±rasÄ±nÄ± koruyan hibrit mimari
- GPU optimize edilmiÅŸ eÄŸitim

**Performans:**
- âœ… **Test DoÄŸruluÄŸu:** %89-92
- âœ… **SÄ±nÄ±f BazÄ±nda F1-Score:** ~%90
- âœ… **BERT Dense Layer'dan %2-4 daha iyi**
- âœ… **Gemini ile yÃ¼ksek uyuÅŸma**

**Model Mimarisi:**
```
BERT Embedding (64 Ã— 768)
    â†“
Bidirectional LSTM (128 units)
    â†“
Bidirectional LSTM (64 units)
    â†“
Dense + Dropout
    â†“
Softmax (3 sÄ±nÄ±f)
```

---

### 3ï¸âƒ£ **LSTM Duygu Analizi**
ğŸ“‚ KlasÃ¶r: `/lstm-sentiment/`

**Ã–zellikler:**
- Saf Bidirectional LSTM mimarisi
- Hafif ve hÄ±zlÄ± model
- Early stopping ve learning rate scheduling
- Gemini ile detaylÄ± karÅŸÄ±laÅŸtÄ±rma

**Performans:**
- âœ… **Test DoÄŸruluÄŸu:** %86.8
- âœ… **Gemini UyuÅŸma:** %87.5
- âœ… **EÄŸitim SÃ¼resi:** ~10 dakika (BERT'ten hÄ±zlÄ±)
- âœ… **Model Boyutu:** 1-2M parametre (BERT: 110M)
- âœ… **Bellek KullanÄ±mÄ±:** 2-3 GB (BERT: 6-8 GB)

**Ã–ne Ã‡Ä±kanlar:**
- En hafif ve hÄ±zlÄ± model
- Kaynak kÄ±sÄ±tlÄ± ortamlar iÃ§in ideal
- Makul performans/verimlilik dengesi

---

### 4ï¸âƒ£ **GAN ile Sentetik Metin Ãœretimi**
ğŸ“‚ KlasÃ¶r: `/gan-text-generation/`

**Ã–zellikler:**
- LSTM tabanlÄ± Generator ve Discriminator
- TÃ¼rkÃ§e Vikipedi verileriyle eÄŸitim
- Cosine similarity ile benzersizlik kontrolÃ¼
- Kalite skorlama sistemi

**Veri Ãœretimi PerformansÄ±:**
- âœ… **Ãœretilen CÃ¼mle:** 1000+ Ã¶zgÃ¼n cÃ¼mle
- âœ… **Ortalama Kelime:** 7-8 kelime/cÃ¼mle
- âœ… **Kalite Skoru:** 0.688/1.0
- âœ… **Benzerlik KontrolÃ¼:** %77 Ã¶zgÃ¼nlÃ¼k

**KullanÄ±m AlanlarÄ±:**
- Veri augmentation
- EÄŸitim veri seti geniÅŸletme
- Sentetik benchmark veri setleri

---

### 5ï¸âƒ£ **Gemini ile Veri Seti OluÅŸturma ve Duygu Analizi**
ğŸ“‚ KlasÃ¶r: `/gemini-dataset-generation/`

**Ã–zellikler:**
- Google Gemini 2.5 Flash API kullanÄ±mÄ±
- Batch generation (100 cÃ¼mle/istek)
- Dual hybrid kalite skorlama (FaktÃ¶rel + Perplexity)
- Semantik benzerlik filtresi

**Ãœretim Metrikleri:**
- âœ… **Ãœretilen CÃ¼mle:** 1000 adet
- âœ… **API Ä°steÄŸi:** 42 batch
- âœ… **SÃ¼re:** 50.5 dakika
- âœ… **Kalite Skoru:** 0.688 ortalama
- âœ… **Sentiment DaÄŸÄ±lÄ±mÄ±:** %40 pozitif, %40 nÃ¶tr, %20 negatif

**Perplexity Modeli:**
- `ytu-ce-cosmos/turkish-gpt2` ile doÄŸallÄ±k kontrolÃ¼

---

## ğŸ†• Sentetik Metin Ãœretimi Modelleri (Teknoloji Haberleri)

### 6ï¸âƒ£ **BERT Masked Language Model (MLM) ile Sentetik Ãœretim**
ğŸ“‚ KlasÃ¶r: `/BERT Modeli Ä°le Sentetik Metin Ãœretimi/`

**Ã–zellikler:**
- `dbmdz/bert-base-turkish-cased` modeli
- Konservatif maskeleme stratejisi (1-3 kelime)
- Temperature sampling (1.2)
- Trigram Ã§eÅŸitlilik kontrolÃ¼ (max 8 tekrar)
- Perplexity filtreleme (eÅŸik: 50.0)

**Ãœretim PerformansÄ±:**
- âœ… **Ãœretim:** 100 â†’ 3000 cÃ¼mle
- âœ… **Tekil Oran:** â‰¥ %95
- âœ… **BERTScore F1:** â‰¥ 0.85
- âœ… **Kelime Kapsama:** â‰¥ %90
- âœ… **Perplexity:** â‰¤ 50 (doÄŸal cÃ¼mleler)

**Avantajlar:**
- YÃ¼ksek kalite ve doÄŸallÄ±k
- BERT anlambilimi ile gÃ¼Ã§lÃ¼ kontrol
- GPU hÄ±zlandÄ±rmasÄ±

---

### 7ï¸âƒ£ **Gemini API ile Sentetik Ãœretim**
ğŸ“‚ KlasÃ¶r: `/Gemini Ä°le Sentetik Metin Ãœretimi/`

**Ã–zellikler:**
- Google Gemini 2.5 Flash API
- AkÄ±llÄ± prompt mÃ¼hendisliÄŸi
- Rate limiting ve retry mekanizmasÄ±
- BERT perplexity filtreleme
- Ã‡oklu kalite kontrol katmanÄ±

**Ãœretim PerformansÄ±:**
- âœ… **Ãœretim:** 100 â†’ 3000 cÃ¼mle (~23-25 dakika)
- âœ… **Tekil Oran:** â‰¥ %90
- âœ… **BERTScore F1:** â‰¥ 0.80
- âœ… **Kelime Kapsama:** â‰¥ %85
- âœ… **API Maliyet:** Ãœcretsiz katman (15 RPM)

**Avantajlar:**
- En yÃ¼ksek anlamsal tutarlÄ±lÄ±k
- DoÄŸal TÃ¼rkÃ§e dilbilgisi
- Minimum kod karmaÅŸÄ±klÄ±ÄŸÄ±

---

### 8ï¸âƒ£ **GPT-2 TÃ¼rkÃ§e ile Sentetik Ãœretim**
ğŸ“‚ KlasÃ¶r: `/Gpt-2 Modeli Ä°le Sentetik Metin Ãœretimi/`

**Ã–zellikler:**
- `ytu-ce-cosmos/turkish-gpt2` (~124M parametre)
- Causal Language Modeling (CLM)
- Batch generation (10 cÃ¼mle/batch)
- Temperature sampling (1.0-1.5)
- KapsamlÄ± regex temizleme (15 katman)

**Ãœretim PerformansÄ±:**
- âœ… **Ãœretim:** 100 â†’ 3000 cÃ¼mle (~22-25 dakika)
- âœ… **Tekil Oran:** â‰¥ %95
- âœ… **BERTScore F1:** â‰¥ 0.75 (CLM iÃ§in)
- âœ… **Ã‡eÅŸitlilik:** Ã‡ok yÃ¼ksek
- âš ï¸ **Temizleme:** YÃ¼ksek gereksinim

**Avantajlar:**
- YÃ¼ksek Ã§eÅŸitlilik
- AkÄ±cÄ± metin Ã¼retimi
- Ãœcretsiz ve hÄ±zlÄ±

---

### 9ï¸âƒ£ **Character-level LSTM ile Sentetik Ãœretim**
ğŸ“‚ KlasÃ¶r: `/LSTM Modeli Ä°le Sentetik Metin Ãœretimi/`

**Ã–zellikler:**
- SÄ±fÄ±rdan eÄŸitilen LSTM (3.74M parametre)
- Character-level tokenization (75 karakter)
- 2 katmanlÄ± Bidirectional LSTM
- Prefix-based generation
- 50 epoch eÄŸitim (~5-10 dakika)

**Ãœretim PerformansÄ±:**
- âœ… **Ãœretim:** 100 â†’ 3000 cÃ¼mle
- âœ… **Tekil Oran:** â‰¥ %90
- âš ï¸ **BERTScore F1:** â‰¥ 0.75 (dÃ¼ÅŸÃ¼k)
- âš ï¸ **Kelime Kapsama:** â‰¥ %80
- âš ï¸ **Perplexity:** â‰¤ 70 (gevÅŸek eÅŸik)

**Avantajlar:**
- En kÃ¼Ã§Ã¼k model (~15 MB)
- HÄ±zlÄ± eÄŸitim (5-10 dk)
- DÃ¼ÅŸÃ¼k GPU memory (~500 MB)

---

### ğŸ”Ÿ **mT5 (Multilingual T5) ile Sentetik Ãœretim**
ğŸ“‚ KlasÃ¶r: `/mT5 Modeli Ä°le Sentetik Metin Ãœretimi/`

**Ã–zellikler:**
- Ä°ki model: `google/mt5-base` (580M) ve `Turkish-NLP/t5-efficient-base-turkish` (220M)
- Encoder-Decoder mimarisi
- Paraphrase, rewrite, generate gÃ¶revleri
- 15 katmanlÄ± agresif temizleme
- Dil filtreleme (Kiril, Yunanca, Ã‡ince)

**Ãœretim PerformansÄ±:**
- âœ… **Ãœretim:** 100 â†’ 3000 cÃ¼mle (~1.5-2 saat)
- âœ… **Tekil Oran:** %100 (mt5-base)
- âš ï¸ **BERTScore F1:** 0.46 (mt5-base iÃ§in dÃ¼ÅŸÃ¼k)
- âš ï¸ **Kelime Kapsama:** %50.81 (mt5-base)
- âœ… **Turkish-NLP T5:** Daha iyi performans

**Avantajlar:**
- Ã‡ok dilli destek (101 dil)
- Task flexibility
- TÃ¼rkÃ§e Ã¶zel model mevcut

---

## ğŸ“Š KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz

### ğŸ† Duygu Analizi Model PerformanslarÄ± (Test Seti)

| Model | Accuracy | Precision | Recall | F1-Score | Gemini UyuÅŸma |
|-------|----------|-----------|--------|----------|---------------|
| **BERT** | **%92.6** ğŸ¥‡ | 0.926 | 0.926 | 0.926 | **%92.3** ğŸ¥‡ |
| **BiLSTM+BERT** | %89-92 ğŸ¥ˆ | ~0.90 | ~0.90 | ~0.90 | YÃ¼ksek |
| **LSTM** | %86.8 ğŸ¥‰ | 0.870 | 0.868 | 0.867 | %87.5 |

### ğŸ†• Sentetik Metin Ãœretimi Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Model | Tekil Oran | BERTScore F1 | Kelime Kapsama | SÃ¼re | Model Boyutu |
|-------|------------|--------------|----------------|------|--------------|
| **BERT MLM** | â‰¥%95 ğŸ¥‡ | â‰¥0.85 ğŸ¥‡ | â‰¥%90 ğŸ¥‡ | Orta | ~500 MB |
| **Gemini API** | â‰¥%90 ğŸ¥ˆ | â‰¥0.80 ğŸ¥ˆ | â‰¥%85 ğŸ¥ˆ | 23-25 dk | - (API) |
| **GPT-2** | â‰¥%95 ğŸ¥‡ | â‰¥0.75 | â‰¥%80 | 22-25 dk | ~500 MB |
| **mT5 (Turkish-NLP)** | %100 ğŸ¥‡ | YÃ¼ksek | YÃ¼ksek | 1-1.5 saat | ~900 MB |
| **mT5 (base)** | %100 ğŸ¥‡ | 0.46 âš ï¸ | %50 âš ï¸ | 1.5-2 saat | ~2.3 GB |
| **Character LSTM** | â‰¥%90 | â‰¥0.75 | â‰¥%80 | DeÄŸiÅŸken | ~15 MB ğŸ¥‡ |
| **GAN** | %77 | - | - | - | DeÄŸiÅŸken |

### âš¡ Verimlilik KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Metrik | BERT | BiLSTM+BERT | LSTM |
|--------|------|-------------|------|
| **EÄŸitim SÃ¼resi** | ~15-20 dk | ~12-15 dk | **~10 dk** âœ… |
| **Model Boyutu** | 110M param | ~60M param | **1-2M param** âœ… |
| **Bellek (GPU)** | 6-8 GB | 4-6 GB | **2-3 GB** âœ… |
| **Ã‡Ä±karÄ±m HÄ±zÄ±** | YavaÅŸ | Orta | **HÄ±zlÄ±** âœ… |

### ğŸ¯ SÄ±nÄ±f BazÄ±nda Performans

#### **Negatif SÄ±nÄ±f** (En BaÅŸarÄ±lÄ±)
- BERT: **%98** ğŸ†
- BiLSTM+BERT: ~%95
- LSTM: %93

#### **Pozitif SÄ±nÄ±f**
- BERT: **%94** ğŸ†
- BiLSTM+BERT: ~%92
- LSTM: %90

#### **NÃ¶tr SÄ±nÄ±f** âš ï¸ (TÃ¼m Modellerde ZayÄ±f)
- BERT: **%84** ğŸ†
- BiLSTM+BERT: ~%82
- LSTM: %75

### ğŸ” Temel Bulgular

#### Duygu Analizi
1. **BERT En YÃ¼ksek DoÄŸruluk**: %92.6 ile en iyi performans
2. **LSTM En Verimli**: En az kaynak, en hÄ±zlÄ± eÄŸitim
3. **BiLSTM+BERT Ä°yi Denge**: Performans-verimlilik dengesi
4. **NÃ¶tr SÄ±nÄ±f Zorlu**: TÃ¼m modellerde iyileÅŸtirme gerekli
5. **Gemini TutarlÄ±lÄ±k YÃ¼ksek**: %87-92 arasÄ± uyuÅŸma

#### Sentetik Metin Ãœretimi
1. **BERT MLM En Kaliteli**: En yÃ¼ksek BERTScore ve kelime kapsama
2. **Gemini En TutarlÄ±**: DoÄŸal TÃ¼rkÃ§e, yÃ¼ksek anlamsal tutarlÄ±lÄ±k
3. **GPT-2 En Ã‡eÅŸitli**: YÃ¼ksek Ã§eÅŸitlilik ama temizleme gerektirir
4. **Character LSTM En Hafif**: 15 MB, dÃ¼ÅŸÃ¼k kaynak kullanÄ±mÄ±
5. **mT5 Dil Sorunu**: mt5-base TÃ¼rkÃ§e'de zayÄ±f, Turkish-NLP modeli Ã¶nerilir
6. **Pre-trained > Scratch**: SÄ±fÄ±rdan eÄŸitilen modeller dÃ¼ÅŸÃ¼k kalite

### ğŸ¤” Hangi Modeli SeÃ§meli?

#### Duygu Analizi Ä°Ã§in
| Senaryo | Ã–nerilen Model | Neden? |
|---------|----------------|--------|
| **Maksimum DoÄŸruluk** | BERT | En yÃ¼ksek accuracy (%92.6) |
| **Mobil/Embedded** | LSTM | En hafif model (1-2M param) |
| **Dengeli Ã‡Ã¶zÃ¼m** | BiLSTM+BERT | Ä°yi performans + kabul edilebilir kaynak |
| **GerÃ§ek ZamanlÄ±** | LSTM | En hÄ±zlÄ± Ã§Ä±karÄ±m sÃ¼resi |

#### Sentetik Metin Ãœretimi Ä°Ã§in
| Senaryo | Ã–nerilen Model | Neden? |
|---------|----------------|--------|
| **Maksimum Kalite** | BERT MLM | En yÃ¼ksek BERTScore (â‰¥0.85) |
| **DoÄŸal TÃ¼rkÃ§e** | Gemini API | LLM ile en tutarlÄ± sonuÃ§lar |
| **Maksimum Ã‡eÅŸitlilik** | GPT-2 | YÃ¼ksek temperature sampling |
| **Minimum Kaynak** | Character LSTM | 15 MB, 500 MB GPU memory |
| **TÃ¼rkÃ§e Ã–zel** | Turkish-NLP T5 | TÃ¼rkÃ§e'ye optimize |
| **Ã‡ok Dilli** | mT5-base | 101 dil (ama TÃ¼rkÃ§e zayÄ±f) |
| **HÄ±z** | Gemini/GPT-2 | ~22-25 dakika |

---

## ğŸ“ Proje YapÄ±sÄ±

```
Sentetik-Veri-Uretimi-NLP/
â”‚
â”œâ”€â”€ README.md                                      # Ana dokÃ¼mantasyon (bu dosya)
â”œâ”€â”€ LICENSE.md                                     # Lisans bilgisi
â”‚
â”œâ”€â”€ ğŸ“Š DUYGU ANALÄ°ZÄ° MODELLERÄ°
â”‚
â”œâ”€â”€ bert-sentiment-analysis/                       # BERT Duygu Analizi
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ egitim-veriseti-5k.xlsx
â”‚   â”œâ”€â”€ bert_vs_gemini_sonuc_1k.xlsx
â”‚   â””â”€â”€ etiketsiz-test-gemini-etiketlenmis-1k.xlsx
â”‚
â”œâ”€â”€ bilstm-bert-hybrid/                            # BiLSTM + BERT Hibrit
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ egitim-veriseti.xlsx
â”‚   â”œâ”€â”€ etiketsiz-test-gemini-etiketlenmis.xlsx
â”‚   â””â”€â”€ bert_vs_gemini_sonuc.xlsx
â”‚
â”œâ”€â”€ lstm-sentiment/                                # LSTM Duygu Analizi
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ egitim-veriseti-5k.xlsx
â”‚   â”œâ”€â”€ lstm_vs_gemini_sonuc_1k.xlsx
â”‚   â””â”€â”€ etiketsiz-test-gemini-etiketlenmis-1k.xlsx
â”‚
â”œâ”€â”€ ğŸ†• SENTETÄ°K METÄ°N ÃœRETÄ°MÄ° MODELLERÄ°
â”‚
â”œâ”€â”€ BERT Modeli Ä°le Sentetik Metin Ãœretimi/        # BERT MLM
â”‚   â”œâ”€â”€ temp.py                                    # Ana script
â”‚   â”œâ”€â”€ README.md                                  # DetaylÄ± dokÃ¼mantasyon
â”‚   â”œâ”€â”€ tekonoloji-haber-baslÄ±klarÄ±.csv            # 100 orijinal cÃ¼mle
â”‚   â”œâ”€â”€ sentetik_teknoloji_haberleri_3000.csv      # 3000 Ã¼retilen cÃ¼mle
â”‚   â””â”€â”€ sentetik_veri_metrikleri.png               # GÃ¶rselleÅŸtirme
â”‚
â”œâ”€â”€ Gemini Ä°le Sentetik Metin Ãœretimi/             # Gemini API
â”‚   â”œâ”€â”€ gemini_sentetik_uretim.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ tekonoloji-haber-baslÄ±klarÄ±.csv
â”‚   â”œâ”€â”€ gemini_sentetik_teknoloji_haberleri_3000.csv
â”‚   â”œâ”€â”€ gemini-cÄ±ktÄ±lar.txt
â”‚   â””â”€â”€ gemini_sentetik_metrikler.png
â”‚
â”œâ”€â”€ Gpt-2 Modeli Ä°le Sentetik Metin Ãœretimi/       # GPT-2
â”‚   â”œâ”€â”€ gpt2_sentetik_uretim.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ tekonoloji-haber-baslÄ±klarÄ±.csv
â”‚   â”œâ”€â”€ gpt2_sentetik_teknoloji_haberleri_3000.csv
â”‚   â””â”€â”€ gpt2-cÄ±ktÄ±lar.txt
â”‚
â”œâ”€â”€ LSTM Modeli Ä°le Sentetik Metin Ãœretimi/        # Character-level LSTM
â”‚   â”œâ”€â”€ lstm_sentetik_uretim.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ tekonoloji-haber-baslÄ±klarÄ±.csv
â”‚   â”œâ”€â”€ lstm_sentetik_teknoloji_haberleri_3000.csv
â”‚   â””â”€â”€ lstm.txt
â”‚
â”œâ”€â”€ mT5 Modeli Ä°le Sentetik Metin Ãœretimi/         # mT5
â”‚   â”œâ”€â”€ t5_turkish_sentetik_uretim.py             # Turkish-NLP model
â”‚   â”œâ”€â”€ t5_sentetik_uretim.py                     # mt5-base model
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ tekonoloji-haber-baslÄ±klarÄ±.csv
â”‚   â”œâ”€â”€ t5_turkish_sentetik_teknoloji_haberleri_3000.csv
â”‚   â”œâ”€â”€ t5_sentetik_teknoloji_haberleri_3000.csv
â”‚   â””â”€â”€ t5-base-duz-model.txt
â”‚
â”œâ”€â”€ gan-text-generation/                           # GAN Metin Ãœretimi (Eski)
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ sentences.txt
â”‚   â”œâ”€â”€ wiki.tr.txt
â”‚   â”œâ”€â”€ uretilen_cumleler.csv
â”‚   â””â”€â”€ training_history.png
â”‚
â”œâ”€â”€ gemini-dataset-generation/                     # Gemini Veri Ãœretimi (Eski)
â”‚   â”œâ”€â”€ main10.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ main10.pdf
â”‚   â””â”€â”€ elektrikli_araba_1000_batch.xlsx
â”‚
â”œâ”€â”€ GAN Modeli Ä°le Metin Ãœretimi/                  # GAN (Ek Ã§alÄ±ÅŸma)
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ LiteratÃ¼rdeki Sentetik Veri Ãœretimi Ä°le Ä°lgili Makaleler/
    â”‚                                              # ğŸ“š LiteratÃ¼r AraÅŸtÄ±rmasÄ±
    â”œâ”€â”€ metin/                                     # Metin tabanlÄ± sentetik veri
    â”‚   â”œâ”€â”€ Genel(arxiv.org vb.)/
    â”‚   â””â”€â”€ ScienceDirect & IEEE Xplore/
    â”‚
    â”œâ”€â”€ gÃ¶rÃ¼ntÃ¼/                                   # GÃ¶rÃ¼ntÃ¼ tabanlÄ± sentetik veri
    â”‚
    â””â”€â”€ ses/                                       # Ses tabanlÄ± sentetik veri
```

---

## ğŸ› ï¸ Kurulum

### Sistem Gereksinimleri

**DonanÄ±m:**
- GPU: NVIDIA GPU (Ã¶nerilen: Tesla T4 veya Ã¼zeri)
- RAM: Minimum 8GB (Ã¶nerilen: 16GB+)
- Depolama: ~5GB (tÃ¼m modeller iÃ§in)

**YazÄ±lÄ±m:**
- Python 3.8+
- CUDA 11.x (GPU iÃ§in)
- pip veya conda

### Temel KÃ¼tÃ¼phaneler

```bash
# TÃ¼m projeler iÃ§in ortak
pip install pandas numpy openpyxl scikit-learn

# BERT projeleri iÃ§in
pip install torch transformers

# LSTM projeleri iÃ§in
pip install tensorflow

# GAN projesi iÃ§in
pip install torch sentence-transformers

# Gemini projesi iÃ§in
pip install google-generativeai
```

### Proje BazÄ±nda Kurulum

Her alt klasÃ¶rdeki README.md dosyasÄ±nda detaylÄ± kurulum talimatlarÄ± mevcuttur.

---

## ğŸš€ KullanÄ±m

### HÄ±zlÄ± BaÅŸlangÄ±Ã§

1. **Repo'yu KlonlayÄ±n**
```bash
git clone https://github.com/kullanici-adi/synthetic-data-generation.git
cd synthetic-data-generation
```

2. **Ä°lgilendiÄŸiniz Projeye Gidin**
```bash
cd bert-sentiment-analysis/  # veya lstm-sentiment, gan-text-generation vb.
```

3. **README TalimatlarÄ±nÄ± Takip Edin**
Her klasÃ¶rdeki README.md dosyasÄ±, o projeye Ã¶zel kurulum ve Ã§alÄ±ÅŸtÄ±rma adÄ±mlarÄ±nÄ± iÃ§erir.

### Kaggle/Colab KullanÄ±mÄ±

TÃ¼m projeler **GPU destekli** ortamlarda en iyi performansÄ± gÃ¶sterir:

1. Kaggle Notebook veya Google Colab aÃ§Ä±n
2. GPU T4 x2 hÄ±zlandÄ±rÄ±cÄ±yÄ± aktif edin
3. Ä°lgili veri setlerini yÃ¼kleyin
4. `main.py` kodunu Ã§alÄ±ÅŸtÄ±rÄ±n

---

## ğŸ“ˆ Performans Metrikleri

### Accuracy (DoÄŸruluk) KarÅŸÄ±laÅŸtÄ±rmasÄ±

```
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 92.6% BERT
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      91.0% BiLSTM+BERT (ortalama)
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         86.8% LSTM
```

### Model Boyutu KarÅŸÄ±laÅŸtÄ±rmasÄ±

```
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 110M BERT
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                               60M BiLSTM+BERT
â–ˆ                                                            1.5M LSTM
```

### EÄŸitim SÃ¼resi (GPU T4 x2)

```
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 20 dk BERT
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      15 dk BiLSTM+BERT
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           10 dk LSTM
```

---

## ğŸ“ Ã–ÄŸrenilen Dersler

### âœ… BaÅŸarÄ±lar

1. **BERT Ã‡ok GÃ¼Ã§lÃ¼**: Transfer learning ile TÃ¼rkÃ§e'de mÃ¼kemmel sonuÃ§lar
2. **LSTM Hala DeÄŸerli**: Kaynak kÄ±sÄ±tlÄ± senaryolar iÃ§in hÄ±zlÄ± ve etkili
3. **Hibrit YaklaÅŸÄ±m Ä°yi**: BiLSTM+BERT denge noktasÄ± saÄŸlÄ±yor
4. **GAN Ã‡alÄ±ÅŸÄ±yor**: TÃ¼rkÃ§e metin Ã¼retimi iÃ§in uygulanabilir
5. **Gemini GÃ¼venilir**: Etiketleme ve karÅŸÄ±laÅŸtÄ±rma iÃ§in tutarlÄ±

### âš ï¸ Zorluklar

1. **NÃ¶tr SÄ±nÄ±f Zor**: TÃ¼m modellerde en dÃ¼ÅŸÃ¼k performans
2. **Pozitif-NÃ¶tr KarÄ±ÅŸÄ±mÄ±**: Model ve Gemini arasÄ±nda en Ã§ok burada farklÄ±lÄ±k
3. **GAN EÄŸitimi Hassas**: Hyperparameter tuning kritik
4. **Kaynak YoÄŸunluÄŸu**: BERT modelleri bÃ¼yÃ¼k GPU bellek gerektiriyor
5. **TÃ¼rkÃ§e Veri KÄ±tlÄ±ÄŸÄ±**: Kaliteli etiketli veri bulmak zorlu

### ğŸ”® Gelecek Ä°yileÅŸtirmeler

- [ ] NÃ¶tr sÄ±nÄ±f iÃ§in Ã¶zel model eÄŸitimi
- [ ] Daha bÃ¼yÃ¼k veri setleri (10K+ cÃ¼mle)
- [ ] Transformer-XL gibi yeni mimariler
- [ ] Multi-task learning yaklaÅŸÄ±mlarÄ±
- [ ] Ensemble modelleme (BERT + LSTM)
- [ ] Fine-tuned TÃ¼rkÃ§e GPT modelleri

---

## ğŸ“š LiteratÃ¼r AraÅŸtÄ±rmasÄ±

Bu proje, sentetik veri Ã¼retimi konusunda kapsamlÄ± bir literatÃ¼r taramasÄ± iÃ§ermektedir. **LiteratÃ¼rdeki Sentetik Veri Ãœretimi Ä°le Ä°lgili Makaleler** klasÃ¶rÃ¼nde, farklÄ± veri tÃ¼rleri iÃ§in akademik Ã§alÄ±ÅŸmalar kategorize edilmiÅŸtir:

### ğŸ“ Metin TabanlÄ± Sentetik Veri
- **Genel**: Ã‡eÅŸitli kaynaklardan derlenen genel Ã§alÄ±ÅŸmalar
- **ScienceDirect & IEEE Xplore**: Akademik veritabanlarÄ±ndan seÃ§ilmiÅŸ makaleler
- GAN, LSTM, BERT ve transformer tabanlÄ± metin Ã¼retimi Ã§alÄ±ÅŸmalarÄ±
- TÃ¼rkÃ§e ve Ã§ok dilli sentetik veri Ã¼retimi yaklaÅŸÄ±mlarÄ±

### ğŸ–¼ï¸ GÃ¶rÃ¼ntÃ¼ TabanlÄ± Sentetik Veri
- Image generation iÃ§in GAN, VAE ve Diffusion modelleri
- Sentetik gÃ¶rÃ¼ntÃ¼ kalite deÄŸerlendirme metrikleri
- Computer vision uygulamalarÄ± iÃ§in veri augmentation

### ğŸ”Š Ses TabanlÄ± Sentetik Veri
- TTS (Text-to-Speech) sistemleri
- Ses senteziyle veri augmentation
- KonuÅŸma tanÄ±ma sistemleri iÃ§in sentetik veri

> **Not**: Bu klasÃ¶r, projenin teorik temelini oluÅŸturan kaynaklardan oluÅŸmaktadÄ±r ve araÅŸtÄ±rmacÄ±lar iÃ§in referans niteliÄŸindedir.

---

## ğŸ“š Referanslar ve Kaynaklar

### Modeller

- **BERT**: [dbmdz/bert-base-turkish-cased](https://huggingface.co/dbmdz/bert-base-turkish-cased)
- **Turkish GPT-2**: [ytu-ce-cosmos/turkish-gpt2](https://huggingface.co/ytu-ce-cosmos/turkish-gpt2)
- **Gemini AI**: [Google DeepMind](https://deepmind.google/technologies/gemini/)

### Veri Setleri

- **TÃ¼rkÃ§e Vikipedi**: [Turkish Sentences Dataset](https://www.kaggle.com/datasets/mahdinamidamirchi/turkish-sentences-dataset)

### KÃ¼tÃ¼phaneler

- **Transformers**: [Hugging Face](https://huggingface.co/docs/transformers/)
- **TensorFlow**: [tensorflow.org](https://www.tensorflow.org/)
- **PyTorch**: [pytorch.org](https://pytorch.org/)

---

## ğŸ¤ KatkÄ±da Bulunma

Bu proje ÅŸu anda **kapalÄ± kaynak** olup, katkÄ±lar kabul edilmemektedir. Ancak:

- ğŸ› Bug bildirimleri iÃ§in Issue aÃ§abilirsiniz
- ğŸ’¡ Ã–neri ve geri bildirimlerinizi paylaÅŸabilirsiniz
- â­ Projeyi beÄŸendiyseniz yÄ±ldÄ±z verebilirsiniz

---

## ğŸ“§ Ä°letiÅŸim

Proje hakkÄ±nda sorularÄ±nÄ±z iÃ§in:

- **GeliÅŸtirici**: Mustafa AtaklÄ±
- **GitHub**: [github.com/kullanici-adi](https://github.com/kullanici-adi)
- **Email**: [email@example.com](mailto:email@example.com)

---

## ğŸ“„ Lisans

```
Bu projenin tÃ¼m haklarÄ± saklÄ±dÄ±r Â© 2025 Mustafa AtaklÄ±.

Ä°zinsiz kullanÄ±mÄ±, kopyalanmasÄ± veya daÄŸÄ±tÄ±mÄ± kesinlikle yasaktÄ±r.
DetaylÄ± bilgi iÃ§in lÃ¼tfen LICENSE.md dosyasÄ±na bakÄ±nÄ±z.
```

---

## â­ YÄ±ldÄ±z Vermeyi UnutmayÄ±n!

Bu projeyi faydalÄ± bulduysanÄ±z, GitHub'da â­ vererek destek olabilirsiniz!

### ğŸ† Proje Ä°statistikleri

#### Duygu Analizi Ã‡alÄ±ÅŸmalarÄ±
- **Modeller**: 4 farklÄ± yaklaÅŸÄ±m (BERT, BiLSTM+BERT, LSTM, GAN)
- **Veri**: 10K+ etiketli cÃ¼mle
- **DoÄŸruluk**: %86.8 - %92.6 arasÄ±

#### Sentetik Metin Ãœretimi Ã‡alÄ±ÅŸmalarÄ±
- **Modeller**: 5 farklÄ± yaklaÅŸÄ±m (BERT MLM, Gemini, GPT-2, Character LSTM, mT5)
- **Veri**: 100 â†’ 3000 cÃ¼mle Ã¼retimi
- **Kalite**: BERTScore 0.46 - 0.85 arasÄ±
- **Toplam Ãœretilen**: 15,000+ sentetik cÃ¼mle

#### Genel Ä°statistikler
- **Toplam Model**: 9 farklÄ± model/yaklaÅŸÄ±m
- **Toplam Kod**: 5000+ satÄ±r Python
- **README DosyalarÄ±**: 10 adet (her model iÃ§in detaylÄ±)
- **GeliÅŸtirme SÃ¼resi**: 4+ ay
- **GPU Saati**: 150+ saat
- **LiteratÃ¼r**: 3 kategori (Metin, GÃ¶rÃ¼ntÃ¼, Ses)
- **Akademik Kaynak**: ScienceDirect & IEEE Xplore